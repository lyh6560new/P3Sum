{
    "output_dir": "/home2/yhliu/simplex-diffusion-main/raw/cnndm/roberta_extend",
    "model_name_or_path": "roberta-base",
    "dataset_name":"cnn_dailymail",
    "dataset_config_name":"3.0.0",
    "cache_dir":"/home2/yhliu",
    "preprocessing_num_workers":16,
    "overwrite_cache":false,
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "do_train": true,
    "do_eval": true,
    "do_predict":false,
    "evaluation_strategy": "steps",
    "eval_steps": 1000,
    "max_seq_length": 1024,
    "max_target_length":120,
    "max_source_length":904,
    "val_max_target_length":50,
    "skip_special_tokens":true,
    "max_eval_samples": 48,
    "max_predict_samples": 48,
    "simplex_value": 5.0,
    "num_diffusion_steps": 5000,
    "num_inference_diffusion_steps": 1000,
    "lr_scheduler_type": "linear",
    "learning_rate": 3e-5,
    "pad_to_max_length": true,
    "beta_schedule": "squaredcos_improved_ddpm",
    "weight_decay": 0.0,
    "top_p": 0.99,
    "max_steps": 200000,
    "gradient_accumulation_steps": 4,
    "warmup_steps": 2000,
    "logging_steps": 50,
    "save_steps": 1000,
    "conditional_generation": "ul2",
    "save_total_limit": 3,
    "tokenized_data_path": "/home2/yhliu/simplex-diffusion-main/raw/cnndm/roberta",
    "report_to":"tensorboard",
    "load_best_model_at_end": true,
    "overwrite_output_dir":false,
    "metric_for_best_model": "pred_texts_from_logits_masked_rouge1",
    "self_condition":"logits_mean"

}
